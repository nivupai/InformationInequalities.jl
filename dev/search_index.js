var documenterSearchIndex = {"docs":
[{"location":"tutorials/entropic2d/#Eigenvalue-computations","page":"Entropic Space","title":"Eigenvalue computations","text":"","category":"section"},{"location":"tutorials/entropic2d/#Generator-matrix","page":"Entropic Space","title":"Generator matrix","text":"","category":"section"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"    using InformationInequalities\n    n=3\n    G,K,L=find_matrixG(n)\n    transpose(G)","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"Note that the generator matrix is K times L ","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"Pictorial view for n=3:","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"    using InformationInequalities\n    using Plots,LinearAlgebra\n    n=3\n    G,K,L=find_matrixG(n)\n    heatmap(transpose(G),xaxis=nothing,yaxis=nothing,legend=nothing,color=:viridis)\n    savefig(\"heatmapH3a.svg\"); # hide ","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"(Image: )","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"Pictorial view for n=4:","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"    using InformationInequalities\n    using Plots,LinearAlgebra\n    n=4\n    G,K,L=find_matrixG(n)\n    #heatmap(transpose(G),aspectratio=1,color=:viridis)\n    heatmap(transpose(G),xaxis=nothing,yaxis=nothing,legend=nothing,color=:viridis)\n    savefig(\"heatmapH4a.svg\"); # hide ","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"(Image: )","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"Pictorial view for n=6:","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"    using InformationInequalities\n    using Plots,LinearAlgebra\n    n=6\n    G,K,L=find_matrixG(n)\n    #heatmap(transpose(G),aspectratio=1,color=:viridis)\n    heatmap(transpose(G),xaxis=nothing,yaxis=nothing,legend=nothing,color=:viridis)\n    savefig(\"heatmapH6a.svg\"); # hide ","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"(Image: )","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"Pictorial view for n=7:","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"(Image: )","category":"page"},{"location":"tutorials/entropic2d/#Singular-values-of-the-Entropic-Space","page":"Entropic Space","title":"Singular values of the Entropic Space","text":"","category":"section"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"The singular values of the generator matrix follows some structure.","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"using LinearAlgebra;\nusing InformationInequalities\nusing Plots\n\tscatter(svdvals(find_matrixG(2)[1]),label=\"Œì2\")\n    scatter!(svdvals(find_matrixG(3)[1]),label=\"Œì3\")\n    scatter!(svdvals(find_matrixG(4)[1]),label=\"Œì4\")\n    scatter!(svdvals(find_matrixG(5)[1]),label=\"Œì5\")\n    ylabel!(\"Œª\")\nsavefig(\"eigsEntropic.svg\"); # hide","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"(Image: )","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"Interesting thing to notice is among the 2^n-n singular values of the generator matrix  of lambda_n, n are inheited from lambda_n-1. The new  eigenvalue is nsqrt2.","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"using LinearAlgebra;\nusing InformationInequalities\n[n*‚àö2 for n=1:10]","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"note: Note\nA fascinating thing here is that, for a given n the number of random variables, the entropy space Gamma_n, the singular values of the generating matrix G are such that n of them are distinct from those of Gamma_n-1 but the rest (overwhleming majority that) are integer multiples of sqrt2.","category":"page"},{"location":"tutorials/entropic2d/#Eigenvalues","page":"Entropic Space","title":"Eigenvalues","text":"","category":"section"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"note: Note\nAt the moment, singularG is not rigorous, that is the computations for the non-interval eigenvalue problem solved internally are carried out using normal non-verified floating point computations. Julia internally has slight difference in floating point precision for some of the singular values when sqrt2 and its multiples are evaluated. TBD","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"To demonstrate the functionality, let us consider the following interval matrix","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"using InformationInequalities\n\nA = [3 2 1\n     2 2 2\n     0 1 2]","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"To get a qualitative evaluation of the enclosure, we can simulate the solution set of mathbfA using Montecarlo, as it is done in the following example","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"using InformationInequalities\nusing LinearAlgebra;\nusing Random; # hide\nRandom.seed!(42) # hide\nusing Plots\nN = 1000\n\nevalues = zeros(ComplexF64, 4, N)\n\nfor i in 1:N\n    evalues[:, i] = eigvals(rand(4,4))\nend\n\nrpart = real.(evalues)\nipart = imag.(evalues)\n\nplot(; ratio=1, label=\"closure\")\nscatter!(rpart[1, :], ipart[1, :]; label=\"Œª‚ÇÅ\")\nscatter!(rpart[2, :], ipart[2, :]; label=\"Œª‚ÇÇ\")\nscatter!(rpart[3, :], ipart[3, :]; label=\"Œª‚ÇÉ\")\nscatter!(rpart[4, :], ipart[4, :]; label=\"Œª‚ÇÑ\")\nxlabel!(\"real\")\nylabel!(\"imag\")\nsavefig(\"eigs1.png\") # hide","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"(Image: )","category":"page"},{"location":"tutorials/entropic2d/","page":"Entropic Space","title":"Entropic Space","text":"Internally, the generical interval eigenvalue problem is","category":"page"},{"location":"references/#all_ref","page":"References","title":"References","text":"","category":"section"},{"location":"references/#[RWYeung2008]","page":"References","title":"[RWYeung2008]","text":"","category":"section"},{"location":"references/","page":"References","title":"References","text":"<ul><li>","category":"page"},{"location":"references/","page":"References","title":"References","text":"Yeung, R. W. (2008). Information Theory and Network Coding (Information Technology: Transmission, Processing and Storage) (2008th ed.). Springer.","category":"page"},{"location":"references/","page":"References","title":"References","text":"<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>","category":"page"},{"location":"references/","page":"References","title":"References","text":"@book{Bathe2014,\n\taddress = {},\n\tauthor = {Yeung, Raymond W},\n\tedition = {1},\n\ttitle = {{Information Theory and Network Coding (Information Technology: Transmission, Processing and Storage)}},\n\tyear = {2008},\n  url  = {https://web.mit.edu/kjb/www/Books/FEP_2nd_Edition_4th_Printing.pdf}\n}","category":"page"},{"location":"references/","page":"References","title":"References","text":"</details></li></ul>","category":"page"},{"location":"references/","page":"References","title":"References","text":"","category":"page"},{"location":"explanations/decomposition/#Information-Measures-in-Canonical-form","page":"Canonical Decomposition","title":"Information Measures in Canonical form","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Pages = [\"decomposition.md\"]","category":"page"},{"location":"explanations/decomposition/#Information-Measures","page":"Canonical Decomposition","title":"Information Measures","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"TBD","category":"page"},{"location":"explanations/decomposition/#Entropy","page":"Canonical Decomposition","title":"Entropy","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"TBD","category":"page"},{"location":"explanations/decomposition/#Mutual-Information","page":"Canonical Decomposition","title":"Mutual Information","text":"","category":"section"},{"location":"explanations/decomposition/#Basic-Information-Measures","page":"Canonical Decomposition","title":"Basic Information Measures","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"TBD","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Conditional Entropy of the form Hleft(mathbfX_amathbfX_bright)\nConditional Mutual Information of the form Ileft(mathbfX_amathbfX_bne imathbfX_cright)","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"where abc subseteq mathcalN_n and ab ne emptyset.","category":"page"},{"location":"explanations/decomposition/#Elemental-Information-Measures","page":"Canonical Decomposition","title":"Elemental Information Measures","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Conditional Entropy of the form Hleft(X_iX_jne iright)\nConditional Mutual Information of the form Ileft(X_iX_jne imathbfX_kappa subseteq mathcalN_nbackslashijright)","category":"page"},{"location":"explanations/decomposition/#Properties-of-IM","page":"Canonical Decomposition","title":"Properties of IM","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Positivity (TBD)","category":"page"},{"location":"explanations/decomposition/#Information-Inequalities","page":"Canonical Decomposition","title":"Information Inequalities","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"f() ge 0 where f is a linear IE (TBD) TBD","category":"page"},{"location":"explanations/decomposition/#Unconstrained-Inequalities","page":"Canonical Decomposition","title":"Unconstrained Inequalities","text":"","category":"section"},{"location":"explanations/decomposition/#Constrained-IE","page":"Canonical Decomposition","title":"Constrained IE","text":"","category":"section"},{"location":"explanations/decomposition/#Information-Constraints","page":"Canonical Decomposition","title":"Information Constraints","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"TBD","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Markov Chain\nIndependence of random variables\nConditional Independence\nFunctional Dependency (Related random variables) Y=fun(X) ","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"A random variable Y is a mapping from another random variable X (TBD)","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"TBD","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Constraints can be expressed linear algebraically Qmathfakh = 0 where Q is the constraint matrix.","category":"page"},{"location":"explanations/decomposition/#Elemental-Information-Inequalities","page":"Canonical Decomposition","title":"Elemental Information Inequalities","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Information Inequalities which belong to any of the following type:","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Conditional Entropy of the form Hleft(X_iX_jne iright)\nConditional Mutual Information of the form Ileft(X_iX_jne imathbfX_kappa subseteq mathcalN_nbackslashijright)","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"are called Elemental Information Inequalities (EIM). These are entropies of a single random variable or and conditional entropies of a single random variable, conditioned on other random variable or sets of random variables. \"","category":"page"},{"location":"explanations/decomposition/#Canonical-Represenation","page":"Canonical Decomposition","title":"Canonical Represenation","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Canonical representation refers to expressing information expression as linear combination of entropies and joint entropies. e.g., H(X1X2X_n). For every Information Expression one find a unique canonical representation.","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Elemental expressions can be decomposed to canonical form as follows:","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Hleft(X_itextbfX_mathcalN backslash iright) = Hleft(textbfX_mathcalNright)\nIleft(X_iX_jtextbfX_kapparight)= Hleft(X_itextbfX_kapparight)+Hleft(X_jtextbfX_kapparight)-Hleft(X_iX_jtextbfX_kapparight)-Hleft(textbfX_kapparight)","category":"page"},{"location":"explanations/decomposition/#Geometry-of-\\Gamma_{n}{*}","page":"Canonical Decomposition","title":"Geometry of Gamma_n^*","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"The region Gamma_n^* is defined as","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Gamma_n^* = bigcup_p in mathcalP mathfrakh(p)","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"where mathcalP is the space of all all probability distributions indued on the random variable space  (TBD. Have to define X_1ldots X_n and its probability space mathcalX_1 ldots mathcalX_n etc.)","category":"page"},{"location":"explanations/decomposition/#Geometry-of-\\Gamma_{n}","page":"Canonical Decomposition","title":"Geometry of Gamma_n","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Gamma_n is the space encapsulating all entropic points. ","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Gamma_n equiv leftmathbfh in mathbbR^2^n-1  mathbfh in mathbbB right","category":"page"},{"location":"explanations/decomposition/#Examples:-Entropic-space-for-\\Gamma_{2}","page":"Canonical Decomposition","title":"Examples: Entropic space for Gamma_2","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"This is easy to visualize. The built in function volumeŒì() can be used to generate and then plot the visualization using plotŒì(n).","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"using InformationInequalities\nplotŒì(n=2,points=yes,max=3,color=:gold)","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"(Image: gamma2-space-points)","category":"page"},{"location":"explanations/decomposition/#Basic-concepts","page":"Canonical Decomposition","title":"Basic concepts","text":"","category":"section"},{"location":"explanations/decomposition/#Entropic-space-for-\\Gamma_{2}","page":"Canonical Decomposition","title":"Entropic space for Gamma_2","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"(Image: gamma2-space-points)","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Consider the linear system","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"mathbfAx=mathbfb","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"TBD the interval linear system by a real matrix C means to multiply both sides of the equation by C, obtaining the new system","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"CmathbfAx=Cmathbfb","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"which is called TBD system. Let us denote by A_c the midpoint matrix of mathbfA. Popular choices for C are","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Inverse midpoint TBD: Capprox A_c^-1\nInverse diagonal TBD: Capprox D_A_c^-1 where D_A_c is the diagonal matrix containing the main diagonal of A_c.","category":"page"},{"location":"explanations/decomposition/#Shannon-Type-Inequalities","page":"Canonical Decomposition","title":"Shannon Type Inequalities","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"TBD An Information inequality of the form f=mathbfb^top mathfrakh ge 0, we just need to check min_mathfrakhGmathfrakh ge 0 mathbfb^top mathfrakh = 0 These are effectively encapsulated to the following optimization problem. This can now be solved using Linear Programming techniques (TBD)","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"The constrained Information Inequality f=mathbfb^top mathfrakh ge 0 with constraint Q mathfrakh =0 can be similarly treated under the optimization framework as,","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"undersetmin_mathfrakhGmathfrakh ge 0Qmathfrakh=0 mathbfb^top mathfrakh = 0","category":"page"},{"location":"explanations/decomposition/#Non-Shannon-Type-Inequalities","page":"Canonical Decomposition","title":"Non Shannon Type Inequalities","text":"","category":"section"},{"location":"explanations/decomposition/#Linear-Programming-and-Duality-principles","page":"Canonical Decomposition","title":"Linear Programming and Duality principles","text":"","category":"section"},{"location":"explanations/decomposition/#Strong-duality","page":"Canonical Decomposition","title":"Strong duality","text":"","category":"section"},{"location":"explanations/decomposition/#Generating-proofs-for-Shannon-Type-Inequalities","page":"Canonical Decomposition","title":"Generating proofs for Shannon Type Inequalities","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Lagrange formulation TBD","category":"page"},{"location":"explanations/decomposition/#Example-of-a-proof-generation","page":"Canonical Decomposition","title":"Example of a proof generation","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Note: The showProof has a rendering display problem on GR/HTML and hence git complaints. Fixme!","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"using InformationInequalities\n#A=\"-3I(X;Y|Z)+2H(X) \\ge 0\"\nshowProof(\"-3I(X;Y|Z)+2H(X)\",Markov(X,Z,Y))","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"!!! Note     To use the function showProof first need to make sure that the inequality is a true Shannon Type inequality. At the moment, the internal check for non-Shannon Tuype inequalities is unstable. FixMe. It is advised to do one pass on oXiTIP or AITIP before trying this. In a later version, a seamless integration is likely.","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"(Image: oxitip_valid_example1) ","category":"page"},{"location":"explanations/decomposition/#Improve-numerical-stability","page":"Canonical Decomposition","title":"Improve numerical stability","text":"","category":"section"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"Even if the algorithms theoretically work","category":"page"},{"location":"explanations/decomposition/","page":"Canonical Decomposition","title":"Canonical Decomposition","text":"TBD: The search space is still double exponential without exploiting any sparsity structure which seems to exisit (TBD). (Image: oxitip_complexity_scale)","category":"page"},{"location":"tutorials/canonical/#Eigenvalue-computations","page":"Canonical Decompositions","title":"Eigenvalue computations","text":"","category":"section"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"For the Information Expression 2H(X1X2X3)+I(X1X2X3)+2H(X1X3)+2I(XY), the canonical representation is -2H(XY)+2H(X)+H(X1X2X3)+3H(X1X3)+H(X2X3)-3H(X3)+2H(Y).","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"using InformationInequalities\nSE=\"2H(X1,X2|X3)+I(X1;X2|X3)+2H(X1,X3)+2I(X;Y)\"\nA5=LinearInformationExpressionToCanonical(SE)\n#plotEntropyTree(A5,curves=false,nodecolor=:skyblue,edgecolor=:gray,nodesize=0.13,nodeshape=:rect,titlefontsize=10,title=latexstring(replace((A5),\"*\"=>\"\",\" \"=>\"\")))\n#savefig(\"gPlotHex1.svg\") # hide","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"(Image: )","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"With simplification simplifyH(A5) we get (Image: )","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"Using the functions PlotIE or PlotInformationExpression, it is easy to visualize the tree graph of the canonical decomposition.","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"using InformationInequalities\nusing LaTeXStrings\nusing Plots\nE=\"2I(X;Y|Z)+3H(Z)\"\n#plotIE(E,nodecolor=:forestgreen)\nplotIE(E,nodecolor=:lightgreen,curves=false,nodesize=0.2,edgecolor=:lightgray,nodeshape=:rect,title=latexstring(LinearInformationExpressionToCanonical(E))); # Hide\nsavefig(\"gplotEx0.svg\");","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"(Image: )","category":"page"},{"location":"tutorials/canonical/#Another-topic-TBD","page":"Canonical Decompositions","title":"Another topic TBD","text":"","category":"section"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"For now duplicate and see if it works (FixMe)","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"Given a (real or complex) interval matrix AinmathbbIC^ntimes n, we define the eigenvalue set ","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"mathbfLambda=lambdainmathbbC lambdatext is an eigenvalue of Atext for some AinmathbfA","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"While characterizing the solution set mathbfLambda (or even its hull) is computationally challenging, the package offers the function TBD which contains an interval box containing mathbfLambda. ","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"note: Note\nAt the moment, eigenbox is not rigorous, that is the computations for the non-interval eigenvalue problem solved internally are carried out using normal non-verified floating point computations.","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"To demonstrate the functionality, let us consider the following interval matrix","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"using InformationInequalities\n\nA = [3 2 1\n     2 2 2\n     0 1 2]","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"To get a qualitative evaluation of the enclosure, we can simulate the solution set of mathbfA using Montecarlo, as it is done in the following example","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"using Random; # hide\nusing LinearAlgebra;\nRandom.seed!(42) # hide\nusing Plots\nN = 1000\n\nevalues = zeros(ComplexF64, 4, N)\n\nfor i in 1:N\n    evalues[:, i] = eigvals(rand(4,4))\nend\n\nrpart = real.(evalues)\nipart = imag.(evalues)\n\nplot(; ratio=1, label=\"enclosure\")\nscatter!(rpart[1, :], ipart[1, :]; label=\"Œª‚ÇÅ\")\nscatter!(rpart[2, :], ipart[2, :]; label=\"Œª‚ÇÇ\")\nscatter!(rpart[3, :], ipart[3, :]; label=\"Œª‚ÇÉ\")\nscatter!(rpart[4, :], ipart[4, :]; label=\"Œª‚ÇÑ\")\nxlabel!(\"real\")\nylabel!(\"imag\")\nsavefig(\"eigs.png\") # hide","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"(Image: )","category":"page"},{"location":"tutorials/canonical/","page":"Canonical Decompositions","title":"Canonical Decompositions","text":"Internally, the generical interval eigenvalue problem is","category":"page"},{"location":"CONTRIBUTING/#InformationInequalities.jl-contribution-guidelines","page":"Contributing","title":"InformationInequalities.jl contribution guidelines","text":"","category":"section"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"First of all, huge thanks for your interest in the package! ‚ú®","category":"page"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"This page has some hopefully useful guidelines. If this is your first time contributing, please read the pull request-workflow section, mainly to make sure everything works smoothly and you don't get stuck with some nasty technicalities. ","category":"page"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"You are also encouraged to read the coding and documentation guidelines, but you don't need to deeply study and memorize those. Core developers are here to help you. Most importantly, relax and have fun!","category":"page"},{"location":"CONTRIBUTING/#Opening-issues","page":"Contributing","title":"Opening issues","text":"","category":"section"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"If you spot something strange in the software (something doesn't work or doesn't behave as expected) do not hesitate to open a bug issue.","category":"page"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"If have an idea of how to make the package better (a new feature, a new piece of documentation, an idea to improve some existing feature), you can open an enhancement issue. ","category":"page"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"In both cases, try to follow the template, but do not worry if you don't know how to fill something. ","category":"page"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"If you feel like your issue does not fit any of the above mentioned templates (e.g. you just want to ask something), you can also open a blank issue.","category":"page"},{"location":"CONTRIBUTING/#Pull-request-workflow","page":"Contributing","title":"Pull request workflow","text":"","category":"section"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"Pull requests are also warmly welcome. For small fixes/additions, feel free to directly open a PR. For bigger more ambitious PRs, it is preferable to open an issue first to discuss it. As a rule of thumb, every pull request should be as atomic as possible (fix one bug, add one feature, address one issue).","category":"page"},{"location":"CONTRIBUTING/#Setup","page":"Contributing","title":"Setup","text":"","category":"section"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"note: Note\nThis is just one way, you can do differently (e.g. clone your fork and add the original repo as upstream). In that case, make sure to use the correct remote names","category":"page"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"This is something that needs to be done only once, the first time you start contributing","category":"page"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"1. From the Julia REPL in package mode (you can enter package mode by typing ]) do","category":"page"},{"location":"CONTRIBUTING/","page":"Contributing","title":"Contributing","text":"pkg> dev InformationInequalities","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: )","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: version)(Image: License: MIT)(Image: Build Status)(Image: Coverage)(Image: bibtex citation)(Image: zenodo doi)","category":"page"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package contains routines to perform numerical linear algebra using interval arithmetic. This can be used both for rigorous computations and uncertainty propagation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"An first overview of the package was given at BLA, the slides are available here.","category":"page"},{"location":"","page":"Home","title":"Home","text":"<iframe style=\"width:560px; height:315px\" src=\"https://www.youtube.com/embed/QHEV9Ie6spo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"page"},{"location":"#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"note: Note\nThe package is still under active development and things evolve quickly (or at least should)","category":"page"},{"location":"","page":"Home","title":"Home","text":"enclosure of the solution of interval linear systems\nexact characterization of the solution set of interval linear systems using \nverified solution of floating point linear systems\nenclosure of eigenvalues of interval matrices\nverified computation of eigenvalues and eigenvectors of floating point matrices","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Open a Julia session and enter","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg; Pkg.add(\"InformationInequalities\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"this will download the package and all the necessary dependencies for you. Next you can import the package with","category":"page"},{"location":"","page":"Home","title":"Home","text":"using InformationInequalities","category":"page"},{"location":"","page":"Home","title":"Home","text":"and you are ready to go.","category":"page"},{"location":"#Quickstart","page":"Home","title":"Quickstart","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using LinearAlgebra, LazySets, Plots\n\nA = [2..4 -1..1; -1..1 2..4]\nb = [-2..2, -1..1]\n\nXenclose = solve(A, b)\npolytopes = solve(A, b, LinearOettliPrager())\n\nplot(UnionSetArray(polytopes), ratio=1, label=\"solution set\", legend=:top)\nplot!(IntervalBox(Xenclose), label=\"enclosure\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: quickstart-example)","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use this package in your work, please cite it as","category":"page"},{"location":"","page":"Home","title":"Home","text":"@software{nrethnakar2022,\nauthor = {\n            Nivedita Rethnakar and\n            Raymond W Yeung\n            Suhas Diggavi\n         },\ntitle  = {InformationInequalities.jl: Exploring Information Theoretic Inequalities},\nmonth  = {1},\nyear   = {2022},\ndoi    = {10.5282/zenodo.5363564},\nurl    = {https://github.com/juliaintervals/InformationInequalities.jl}\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = InformationInequalities","category":"page"},{"location":"#InformationInequalities","page":"Home","title":"InformationInequalities","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for InformationInequalities.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [InformationInequalities]","category":"page"},{"location":"#InformationInequalities.ConditionalEntropyList","page":"Home","title":"InformationInequalities.ConditionalEntropyList","text":"List down all conditional Entropy expressions for a given number n of random variables. Conditional Entropies are of the form H(X,Y|Z) \n\njulia> ConditionalEntropyList(2,\"üçâ\")\n[\"H(üçâ1)\" \"H(üçâ1|üçâ2)\" \"H(üçâ2)\" \"H(üçâ2|üçâ1)\"]\n\njulia> ConditionalEntropyList(2)\n[\"H(X1)\" \"H(X1|X2)\" \"H(X2)\" \"H(X2|X1)\"]\n\njulia> ConditionalEntropyList(3,\"diceüí†\")\n[\"H(diceüí†1)\"\n\"H(diceüí†1|diceüí†2)\"\n\"H(diceüí†1|diceüí†2,diceüí†3)\"\n\"H(diceüí†1|diceüí†3)\"\n\"H(diceüí†2)\"\n\"H(diceüí†2|diceüí†1)\"\n\"H(diceüí†2|diceüí†1,diceüí†3)\"\n\"H(diceüí†2|diceüí†3)\"\n\"H(diceüí†3)\"\n\"H(diceüí†3|diceüí†1)\"\n\"H(diceüí†3|diceüí†1,diceüí†2)\"\n\"H(diceüí†3|diceüí†2)\"]\n\njulia> ConditionalEntropy(3,\"Z\")\n[\"H(Z1)\"\n\"H(Z1|Z2)\"\n\"H(Z1|Z2,Z3)\"\n\"H(Z1|Z3)\"\n\"H(Z2)\"\n\"H(Z2|Z1)\"\n\"H(Z2|Z1,Z3)\"\n\"H(Z2|Z3)\"\n\"H(Z3)\"\n\"H(Z3|Z1)\"\n\"H(Z3|Z1,Z2)\"\n\"H(Z3|Z2)\"]\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.ConditionalMutualInformationList","page":"Home","title":"InformationInequalities.ConditionalMutualInformationList","text":"List all conditional Mutual Information expressions for a given number n of random variables. Conditional Entropies are of the form I(X;Y|Z) aka Mutual information between X and Y given Z. \n\njulia> ConditionalMutualInformationList(2,\"üçâ\")\n[\"I(üçâ1;üçâ2)\" \"I(üçâ2;üçâ1)\"]\njulia> ConditionalMutualInformationList(3)\n[\"I(X1;X2)\",\"I(X1;X2|X3)\",\"I(X1;X3)\",\"I(X1;X3|X2)\",\"I(X2;X1)\",\"I(X2;X1|X3)\",\"I(X2;X3)\",\"I(X2;X3|X1)\",\"I(X3;X1)\",\"I(X3;X1|X2)\",\"I(X3;X2)\",\"I(X3;X2|X1)\"]\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.Elemental2Canonical","page":"Home","title":"InformationInequalities.Elemental2Canonical","text":"Elemental2Canonical(s::String=\"I(Xi;Xüê¨|œÄ)\")\n\nConvert elemental Information measure to canonical form. If s is unspecified, it performs a default expression.\n\nExamples\n\njulia> Elemental2Canonical(\"I(Xi;Xüê¨|œÄ)\")\n\"H(Xi,œÄ)+H(Xüê¨,œÄ)-H(Xi,Xüê¨,œÄ)-H(œÄ)\"\n\njulia> Elemental2Canonical(\"H(Xi,X2|œÄ,Œ≤)\")\n\"H(Xi,X2,œÄ,Œ≤) - H(œÄ,Œ≤)\"\n\njulia>Elemental2Canonical(\"I(Xi;X2,œÅ,üçé|ZœÄ,Œ≤,üç©)\")\n\"H(Xi,ZœÄ,Œ≤,üç©)+H(X2,œÅ,üçé,ZœÄ,Œ≤,üç©)-H(Xi,X2,œÅ,üçé,ZœÄ,Œ≤,üç©)-H(ZœÄ,Œ≤,üç©)\"\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.Elemental2Canonical_H","page":"Home","title":"InformationInequalities.Elemental2Canonical_H","text":"Elemental2Canonical_H(s::String=\"I(Xi;Xüê¨|œÄ)\") Convert a Entropy or Conditional entropy expression s to elemental form. If s is unspecified, it performs a default expression.\n\nExamples\n\njulia> Elemental2Canonical_H(\"H(Xi,Xüê¨|œÄ,Œ≥)\")\n\"H(Xi,Xüê¨,œÄ,Œ≥)-H(œÄ,Œ≥)\"\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.Elemental2Canonical_MI","page":"Home","title":"InformationInequalities.Elemental2Canonical_MI","text":"MutualInformation_ElemToCanon(s::String=\"I(Xi;Xüê¨|œÄ)\")\n\nConvert a mutual information expression s to elemental form. If s is unspecified, it performs a default expression.\n\nExamples\n\njulia> Elemental2Canonical(\"I(Xi;Xüê¨|œÄ)\")\n\"H(Xi,œÄ)+H(Xüê¨,œÄ)-H(Xi,Xüê¨,œÄ)-H(œÄ)\"\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.ElementalMeasures","page":"Home","title":"InformationInequalities.ElementalMeasures","text":"List of Elemental Information measures (EIM) for a given n number of random variables. EIM comprise of conditional entropies H(X1...,Xn|Y1...Ym) and conditional mutual information I(X‚ÇÅ...X‚Çô;Y‚ÇÅ....Y‚Çò|Z‚ÇÅ...Z‚Çñ) measures.\n\njulia> ElementalMeasures(2)\n[\"H(X1)\",\"H(X1|X2)\",\"H(X2)\",\"H(X2|X1)\",\"I(X1;X2)\",\"I(X2;X1)\"]\n\njulia> ElementalMeasures(3,\"üêò\")\n[\"H(üêò1)\"\n\"H(üêò1|üêò2)\"\n\"H(üêò1|üêò2,üêò3)\"\n\"H(üêò1|üêò3)\"\n\"H(üêò2)\"\n\"H(üêò2|üêò1)\"\n\"H(üêò2|üêò1,üêò3)\"\n\"H(üêò2|üêò3)\"\n\"H(üêò3)\"\n\"H(üêò3|üêò1)\"\n\"H(üêò3|üêò1,üêò2)\"\n\"H(üêò3|üêò2)\"\n\"I(üêò1;üêò2)\"\n\"I(üêò1;üêò2|üêò3)\"\n\"I(üêò1;üêò3)\"\n\"I(üêò1;üêò3|üêò2)\"\n\"I(üêò2;üêò1)\"\n\"I(üêò2;üêò1|üêò3)\"\n\"I(üêò2;üêò3)\"\n\"I(üêò2;üêò3|üêò1)\"\n\"I(üêò3;üêò1)\"\n\"I(üêò3;üêò1|üêò2)\"\n\"I(üêò3;üêò2)\"\n\"I(üêò3;üêò2|üêò1)\"]\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.GeometryConeGamma2-Tuple{Any, Any, Any}","page":"Home","title":"InformationInequalities.GeometryConeGamma2","text":"Œì‚ÇÇ geometry. This is the simplest case with two random variables (say X,Y) forming a geometry in three dimension. The geometric space is spanned by entropy vectors H(X), H(Y) and H(X,Y). Œì‚ÇÇ is a 3D cone in the positive orthant. This function is used for visualizing the entropic space in 3D.\n\n\n\n\n\n","category":"method"},{"location":"#InformationInequalities.LinearInformationExpressionToCanonical-Tuple{Any}","page":"Home","title":"InformationInequalities.LinearInformationExpressionToCanonical","text":"LinearInformationExpressionToCanonical(A)\n\njulia>LinearInformationExpressionToCanonical(\"I(X;Y|Z)-2.3H(U,V)-2H(u)\")\n\"1H(X,Z)+1H(Y,Z)-1H(X,Y,Z)-1H(Z)-2.3H(U,V)-2H(u)\"\n\n\n\n\n\n","category":"method"},{"location":"#InformationInequalities.elementsGamma2-Tuple{}","page":"Home","title":"InformationInequalities.elementsGamma2","text":"Set of discrete points in Œì‚ÇÇ\t confined within a hypercube \n\n\n\n\n\n","category":"method"},{"location":"#InformationInequalities.entropic_matrix","page":"Home","title":"InformationInequalities.entropic_matrix","text":"Find the Entropic matrix Gfor a givenn`\n\njulia> entropic_matrix(3)\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.entropy_vector","page":"Home","title":"InformationInequalities.entropy_vector","text":"For a given number n of random variables, list down all the elemental information measures and their corresponding entropic decompositions. The entropic vectors are identified with the prefix h and follows lexicographic mapping. e.g., H(X1,X3,X7)=h137. Note that, for now this lexicographic mapping works only for n < 10.  \n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.find_entropic_vector","page":"Home","title":"InformationInequalities.find_entropic_vector","text":"Given a linear expression in canonical form, it finds the co-ordinates in the entropic space Œì\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.find_matrixG","page":"Home","title":"InformationInequalities.find_matrixG","text":"Find the Entropic matrix G for a given n\n\njulia> find_matrixG(3)\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.find_subset","page":"Home","title":"InformationInequalities.find_subset","text":"find_subset(n::Int64,p,q,RV::AbstractString=\"X\")\n\nGiven i and j compute Œö ‚äÜ ùí© \\{i,j}; i.e., all non exclusive subsets. i,j can also be empty (i.e. []), in which case the non-empty superset gets listed. An optional prefix can be added (default is X).  \n\nExamples\n\njulia>find_subset(4,1,3,\"X\")\n[\"\" \"X1\" \"X1,X2\" \"X1,X2,X5\" \"X1,X5\" \"X2\" \"X2,X5\" \"X5\"]\n\njulia>find_subset(4,1,3,\"\")\n[\"\" \"1\" \"1,2\" \"1,2,5\" \"1,5\" \"2\" \"2,5\" \"5\"]\n\njulia> find_subset(5,4,3,\"üçí\")\n[\"\" \"üçí3\" \"üçí3,üçí4\" \"üçí4\"]\n\njulia> find_subset(5,[],[],\"üçì\")\n[\"üçì1\" \"üçì1,üçì2\" \"üçì1,üçì2,üçì3\" \"üçì1,üçì3\" \"üçì2\" \"üçì2,üçì3\" \"üçì3\"]\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.minimal_EIM_list_canonical","page":"Home","title":"InformationInequalities.minimal_EIM_list_canonical","text":"For a given number n of random variables, list down all the elemental information measures in minimal canonical form. \n\njulia> u,v,m,n=minimal_EIM_list_canonical(2)\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.numEIM","page":"Home","title":"InformationInequalities.numEIM","text":"For a given number n of random variables, list down the maximum number of elemental information measures in minimal canonical form. \n\njulia> u,v,m,n=numEIM(2)\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.order_entropic","page":"Home","title":"InformationInequalities.order_entropic","text":"Each entropy word in an entropic vector is sorted.\n\nExamples\n\njulia> order_entropic(\"h24-h32-h132-h2\")\n\"h24 - h23 - h123 - h2\"\n\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.order_entropic1","page":"Home","title":"InformationInequalities.order_entropic1","text":"Each entropy word in an entropic vector is sorted.\n\nExamples\n\njulia> order_entropic1(\"h24-h32-h132-h2\")\n\"h24 - h23 - h123 - h2\"\n\njulia> order_entropic1(\"7h32 - h243 - h13701 - h92252\")\n\"7h23-h234-h01137-h22259\"\n\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.order_entropic_expression","page":"Home","title":"InformationInequalities.order_entropic_expression","text":"Express an entropic expression in the lexicographic order of entropic vectors\n\njulia> order_entropic_expression(\"h12-h32-123\")\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.order_string","page":"Home","title":"InformationInequalities.order_string","text":"Each word in a sentence (string) is sorted alphabetically.\n\nExamples\n\njulia> order_string(\"This is a sorted sentence; Who is 1 and two  \")\n\" This is a deorst ;ceeennst Who is 1 adn otw  \"\n\n\n\n\n\n\n","category":"function"},{"location":"#InformationInequalities.plotEntropyTree-Tuple{Any}","page":"Home","title":"InformationInequalities.plotEntropyTree","text":"plotEntropyTree(S,...)\n\njulia>plotEntropyTree(\"H(X,Y)+1.2 H(X)+7H(X1,X2,X3)\")\n\njulia>plotEntropyTree(\"H(X,Y)+1H(X1,X2)+3H(X1,X2,X3)\",curves=:false,nodecolor=:gold,edgecolor=:gray,nodeshape=:rect,nodesize=0.15)\n\n\n\n\n\n","category":"method"},{"location":"#InformationInequalities.plotIE-Tuple{Any}","page":"Home","title":"InformationInequalities.plotIE","text":"plotIE(S,...)\n\njulia>PlotIE(\"H(X,Y)+7H(X1,X2,X3)\")\n\njulia>plotIE(\"I(X;Y)+2I(X;Y|Z)\",curves=:false)\n\n\n\n\n\n","category":"method"},{"location":"#InformationInequalities.plotInformationExpression-Tuple{Any}","page":"Home","title":"InformationInequalities.plotInformationExpression","text":"PlotInformationExpression(S,...)\n\njulia>PlotInformationExpression(\"H(X,Y)+7H(X1,X2,X3)\")\n\njulia>PlotInformationExpression(\"I(X;Y)+2I(X;Y|Z)\",curves=:false)\n\n\n\n\n\n","category":"method"},{"location":"#InformationInequalities.unique_entropy_vector","page":"Home","title":"InformationInequalities.unique_entropy_vector","text":"For a given number n<10 of random variables, list down all the unique elemental information measures and their corresponding entropic decompositions. The entropic vectors are identified with the prefix h and follows lexicographic mapping. e.g., H(X1,X3,X7)=h137. Note that, for now this lexicographic mapping works only for n < 10.  \n\n\n\n\n\n","category":"function"},{"location":"explanations/oxitip/#Machine-based-methods-to-verify-and-prove-Information-Inequalities","page":"oXitip: Machine Proof Checker","title":"Machine based methods to verify and prove Information Inequalities","text":"","category":"section"},{"location":"explanations/oxitip/","page":"oXitip: Machine Proof Checker","title":"oXitip: Machine Proof Checker","text":"Pages = [\"oxitip.md\"]","category":"page"},{"location":"explanations/oxitip/#Machine-based-Information-Inequalities-Prover","page":"oXitip: Machine Proof Checker","title":"Machine based Information Inequalities Prover","text":"","category":"section"},{"location":"explanations/oxitip/","page":"oXitip: Machine Proof Checker","title":"oXitip: Machine Proof Checker","text":"TBD Discuss the framework, various known tools ITIP, XiTIP, oXiTiP, AITIP","category":"page"},{"location":"explanations/oxitip/","page":"oXitip: Machine Proof Checker","title":"oXitip: Machine Proof Checker","text":"Limitations (verifier vs proof etc.,)","category":"page"},{"location":"explanations/oxitip/#Basic-concepts-of-ITIP-based-methods","page":"oXitip: Machine Proof Checker","title":"Basic concepts of ITIP based methods","text":"","category":"section"},{"location":"explanations/oxitip/","page":"oXitip: Machine Proof Checker","title":"oXitip: Machine Proof Checker","text":"Yeung's framework, entropic TBD.","category":"page"},{"location":"explanations/oxitip/#Extend-usability-of-algorithms","page":"oXitip: Machine Proof Checker","title":"Extend usability of algorithms","text":"","category":"section"},{"location":"explanations/oxitip/","page":"oXitip: Machine Proof Checker","title":"oXitip: Machine Proof Checker","text":"Some algorithms require the matrix to have a specific structure in order to be used. TBD.","category":"page"},{"location":"explanations/oxitip/#Improve-numerical-stability","page":"oXitip: Machine Proof Checker","title":"Improve numerical stability","text":"","category":"section"},{"location":"explanations/oxitip/","page":"oXitip: Machine Proof Checker","title":"oXitip: Machine Proof Checker","text":"Even if the algorithms theoretically work","category":"page"}]
}
